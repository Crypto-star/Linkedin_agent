# ğŸ“˜ Approach, Challenges & Solutions â€“ *LinkedIn Analyzer (LangGraph + GPT)*

## ğŸ“Œ Overview

This document outlines the **strategic approach**, key **implementation decisions**, **challenges encountered**, and the corresponding **solutions** while building the LinkedIn Analyzer â€” an AI-powered Streamlit app that analyzes LinkedIn profiles, compares them against job descriptions, and offers career advice using GPT and LangGraph.

---

## ğŸ§­ Approach

### 1. **Objective Definition**

The goal was to create a **LinkedIn Career Assistant** that:

* Analyzes LinkedIn profile data intelligently
* Accepts optional job descriptions for comparison
* Maintains contextual conversation memory
* Uses prompt-level guidance to stay domain-specific

---

### 2. **Component Breakdown**

| Module       | Role                                                               |
| ------------ | ------------------------------------------------------------------ |
| `main.py`    | Streamlit app entry point, manages user input, state, and UI flow  |
| `utils.py`   | Handles LinkedIn scraping via Apify and formats profile summaries  |
| `prompts.py` | Constructs dynamic prompts for the GPT model                       |
| `nodes.py`   | Defines LangGraph nodes for chatting and summarizing conversations |
| `.env/.toml` | API key management                                                 |

---

### 3. **Flow Design (LangGraph Integration)**

LangGraph is used to structure the conversation pipeline:

* **`chat_node()`** generates GPT responses using profile + job + chat history
* **`summarizer_node()`** compresses past messages into a summary to prevent context overflow
* Graph edges are connected:
  `chat â†’ summarizer â†’ END`
  This loop retains memory intelligently across multiple turns.

---

### 4. **Streamlit UI Logic**

* Accepts a **LinkedIn profile URL** (scraped once per session)
* Optionally accepts a **Job Description**
* Renders a **chat interface**
* Displays chat history and invokes LangGraph on user input

---

## ğŸš§ Challenges & Solutions

| **Challenge**                                                | **Solution**                                                                                                          |
| ------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------- |
| âš ï¸ Scraping LinkedIn reliably                                | Used [Apify actor](https://apify.com/supreme_coder/linkedin-profile-scraper) with error handling + single-run caching |
| ğŸ§  Maintaining long chat memory across turns                 | Used LangGraphâ€™s state machine with summarization node to persist intent context                                      |
| âŒ Preventing off-topic queries (e.g., politics, trivia)      | Designed strict prompt instructions in `prompts.py` to enforce domain-specific interaction                            |
| ğŸª› Making GPT context-aware without overloading input tokens | Used summarization node + dynamic prompt building with only relevant info                                             |
| ğŸ’¬ Getting useful outputs without hallucination or vagueness | Injected detailed profile summaries and job comparisons into prompts with formatting                                  |
| ğŸ§ª Preventing scraping on every input change                 | Cached profile in `st.session_state` after initial fetch                                                              |
| ğŸ”„ UI becoming unresponsive during scraping                  | Used `st.spinner()` with graceful error handling                                                                      |
| ğŸ” Avoiding API key exposure during deployment               | Used `.env` for local, and `.streamlit/secrets.toml` for Streamlit Cloud                                              |
| ğŸ§± Keeping code modular and testable                         | Segregated scraper, prompts, nodes, and frontend logic into separate files                                            |

---

## ğŸ’¡ Notable Design Choices

* **LangGraph Over Vanilla Chat:**
  Using LangGraph instead of a flat LLM chat allows for custom memory, dynamic routing, and scalability.

* **Apify as Scraper:**
  Avoids the hassle of building a LinkedIn scraper from scratch, ensures compliance with rate limits and session handling.

* **Profile Summary Generator:**
  Summarizing large JSON objects from LinkedIn into formatted, human-readable text improved GPT understanding and reduced token cost.

* **Prompt Guardrails:**
  Prevents the assistant from drifting into irrelevant conversations, ensuring high-quality domain-specific responses.

---

## ğŸ“ Key Learnings

* Prompt engineering is **not just about instructions**, but also about **selective input construction**.
* LangGraph provides a scalable structure to **manage memory, summarization, and complex state flows**.
* Combining multiple tools (Streamlit, LangGraph, Apify, OpenAI) with clear boundaries makes debugging and iteration faster.

---

## ğŸ Final Results

* âœ… Functional and intelligent LinkedIn Analyzer chatbot
* âœ… Real-time scraping integration with GPT analysis
* âœ… Deployable on Streamlit Cloud with `.env` secrets
* âœ… Scalable architecture for future features like resume generation, skill path planning, etc.

---

## ğŸ‘¤ Author

**Harshvardhan Sharma ğŸ˜€âœŒï¸âœŒï¸**
